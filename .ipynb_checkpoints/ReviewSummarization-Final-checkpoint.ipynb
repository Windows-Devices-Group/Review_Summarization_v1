{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61af541e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "import io\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.vectorstores import VectorStoreRetriever\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain_core.messages import HumanMessage\n",
    "from openai import AzureOpenAI\n",
    "import gradio as gr\n",
    "import streamlit as st\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import numpy as np\n",
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.vectorstores import VectorStoreRetriever\n",
    "from langchain.chains import RetrievalQA\n",
    "# from langchain.llms import AzureOpenAI\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "import openai\n",
    "import pyodbc\n",
    "import urllib\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import keyring\n",
    "from azure.identity import InteractiveBrowserCredential\n",
    "from pandasai import SmartDataframe\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "import base64\n",
    "import spacy\n",
    "from pandasql import sqldf\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"a22e367d483f4718b9e96b1f52ce6d53\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://hulk-openai.openai.azure.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb1ecb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load DataFrames from checkpoint files using pickle\n",
    "with open(\"New_DSDBackend_checkpoint.pkl\", \"rb\") as f:\n",
    "    New_DSDBackend = pickle.load(f)\n",
    "\n",
    "with open(\"New_Consolidated_checkpoint.pkl\", \"rb\") as f:\n",
    "    New_Consolidated = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f20e29b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_txt_text(txt_file_path):\n",
    "    with io.open(txt_file_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    return text\n",
    "def get_text_chunks(text):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000)\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    print(len(chunks))\n",
    "    return chunks\n",
    "def get_vector_store(chunks):\n",
    "    embeddings = AzureOpenAIEmbeddings(azure_deployment=\"Embedding-Model\")\n",
    "    vector_store = FAISS.from_texts(chunks, embedding=embeddings)\n",
    "    vector_store.save_local(\"faiss-index\")\n",
    "def get_conversational_chain_summary():\n",
    "    prompt_template = \"\"\"\n",
    "    1.    1. Your will receive some customer reviews about the devices and that too about a particular aspect as an user input\n",
    "    2. These are the only aspects : Performance, Design, Audio, Battery, Camera, Connectivity, Display, Customer Service, Gaming, Graphics, Hardware, Keyboard, Touchpad, Ports, Price, Software, Storage/Memory\n",
    "    3. Your Job is to Summarize the reviews that you get as a user input into 4 to 5 lines as a paragraph and also get some actionable raw (Actual things received as a reviews) reviews based on the reviews that users are mentioning\n",
    "    4. The response should always be summary of review in 10 to 15 line Paragraph. Summary should be only about the aspect that user asked\n",
    "    5. If user asks about Performance aspect, Just focus on the performance aspect. Summarize the user input that are only talking about the aspect that user asks. Your review should only focus on the performance if the user question is regarding performance\n",
    "    \n",
    "    \n",
    "    Also with the summary create Pros and Cons of that aspect in that device.\n",
    "    IMPORTANT : Your response should be Summary of that aspect, Pros : List down max 5 points, Cons : List down max 5 points in the form of table\n",
    "    \n",
    "    IMPORTANT : Use only the data that you are provided with and don't use your pre-trained documents. If the respose for the user question is not in the context, Just Provide \"Not in the context\" \n",
    "    \n",
    "    Context:\\n {context}?\\n\n",
    "    Question: \\n{question}\\n\n",
    " \n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    model = AzureChatOpenAI(\n",
    "    azure_deployment=\"Verbatim-Synthesis\",\n",
    "    api_version='2023-12-01-preview',temperature = 0)\n",
    "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "    chain = load_qa_chain(model, chain_type=\"stuff\", prompt=prompt)\n",
    "    return chain\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"a22e367d483f4718b9e96b1f52ce6d53\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://hulk-openai.openai.azure.com/\"\n",
    "\n",
    "def query_to_embedding_summarize(user_question, txt_file_path):\n",
    "    text = get_txt_text(txt_file_path)\n",
    "    print(text)\n",
    "    chunks = get_text_chunks(text)\n",
    "    print(len(chunks))\n",
    "    get_vector_store(chunks)\n",
    "    embeddings = AzureOpenAIEmbeddings(azure_deployment=\"Embedding-Model\")\n",
    "    \n",
    "    # Load the vector store with the embeddings model\n",
    "    new_db = FAISS.load_local(\"faiss-index\", embeddings, allow_dangerous_deserialization=True)\n",
    "    docs = new_db.similarity_search(user_question)\n",
    "    # Rest of the function remains unchanged\n",
    "    chain = get_conversational_chain_summary()\n",
    "    response = chain({\"input_documents\": docs, \"question\": user_question}, return_only_outputs=True)\n",
    "    return response\n",
    "\n",
    "def query_verbatims(review):\n",
    "    SQL_Query_Temp = client.completions.create(model=deployment_name, prompt=start_phrase_verbatim+review, max_tokens=1000,temperature=0)\n",
    "    SQL_Query = SQL_Query_Temp.choices[0].text\n",
    "    st.write(str(SQL_Query))\n",
    "    return str(SQL_Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca18c985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"a22e367d483f4718b9e96b1f52ce6d53\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://hulk-openai.openai.azure.com/\"\n",
    "client = AzureOpenAI(\n",
    "api_key=os.getenv(\"a22e367d483f4718b9e96b1f52ce6d53\"),  \n",
    "api_version=\"2024-02-01\",\n",
    "azure_endpoint = os.getenv(\"https://hulk-openai.openai.azure.com/\")\n",
    ")\n",
    "\n",
    "deployment_name='SurfaceGenAI'\n",
    "\n",
    "start_phrase_verbatim = \"\"\"\n",
    "\n",
    "    1. Your Job is to convert the user question to SQL Query (Follow Microsoft SQL server SSMS syntax.). You have to give the query so that it can be used on Microsoft SQL server SSMS.YOu have to only return query as a result.\n",
    "    2. There is one table with table name New_Consolidated, which tells about the reviews of differnt devices,  sentiment of the review , Aspect that review is about and related keywords for that aspect . It has following columns: They are\n",
    "        ReviewDateFormatted - Tells about the date/month/year at which the reviews was posted\n",
    "        Sentiment - Tells whether the review is Positive/Negative/Neutral\n",
    "        Geography - From which country the review is posted\n",
    "        FormFactor - Physical Structure of the device\n",
    "        review count - It will be one for each row\n",
    "        SentimentScore - Either 1 or 0 or 1 based on the sentiment\n",
    "        OS - Operating system the device runs with \n",
    "        Sentence - Actual review\n",
    "        Aspect - Category that the review is talking about\n",
    "            These are the only aspects : Performance, Design, Audio, Battery, Camera, Connectivity, Display, Customer Service, Gaming, Graphics, Hardware, Keyboard, Touchpad, Ports, Price, Software, Storage/Memory\n",
    "        Keywords - Important word related to that keyword\n",
    "        OEM - Original Equipment manufacturer of the device (HP, Lenovo, Dell,...)\n",
    "        DeviceFamilyName - Actual Name of the device\n",
    "    3. Net Sentiment of any product is calculated by sum of SentimentScore divided by sum of ReviewCount of the product\n",
    "        (cast(Sum(SentimentScore) as float)/cast(sum(ReviewCount)as float)) * 100\n",
    "    4. Aspect Sentiment of any product is calculated by sum of sentiment score of that aspect divided by sum of ReviewCount of that aspect\n",
    "    5. Net Sentiment and Aspect sentiment should be in Percentage\n",
    "    6. Always use 'LIKE' operator whenever they mention about any device or Aspects. \n",
    "        IMPORTANT : And if the aspect is \"All\" aspect don't apply where condition on Aspect column. Apply Where condition on DeviceFamilyName column.\n",
    "        Example : Aspect LIKE %gaming% and DeviceFamilyName LIKE %Surface Pro 9%\n",
    "    7. If user query is regarding review count of a device, it should be sum(ReviewCount) and if it is regarding sentiment score, it should be sum of SentimentScore\n",
    "    8. Make sure to Give the result as the query so that it can be used on Microsoft SQL server SSMS\n",
    "    9. Every time when we are gettig any results order them based on ReviewCount.\n",
    "    10. When you are giving aspect sentiment or net sentiment along with them give their net sentiment or aspect sentiment. Net sentiment/Aspect Sentiment is just a number which don't make sense to read without review count\n",
    "        For Example if you are giving (SUM(Performance_ASS)/SUM(Performance_ARC))*100 AS 'Performance Sentiment' also in the next column give me Performance_ARC\n",
    "        and Net sentiment also in next column provide sum(ReviewCount)\n",
    "    11. Round off all the decimal values to 1 for Net Sentiment and Aspect Sentiment\n",
    "    12. User Question will always be retriving certain rows from distinct Sentence column based on the certain aspect, devivefamilyname or other filter.\n",
    "    13. You have to write a SQL query to retrive certain rows from distict sentence column.\n",
    "    \n",
    "    User Question :\n",
    "    \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78dec4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-16 19:33:57.259 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n"
     ]
    }
   ],
   "source": [
    "st.title(\"Verbatim Synthesis Tool\")\n",
    "aspect_names = ['All', 'Performance', 'Design', 'Audio', 'Battery', 'Camera', 'Connectivity', 'Display', 'Customer Service','Gaming', 'Graphics', 'Hardware', 'Keyboard', 'Touchpad', 'Ports', 'Price', 'Software', 'Storage/Memory']\n",
    "st.markdown(\"Enter the device name <span style='color: red'>*</span>:\", unsafe_allow_html=True)\n",
    "device_name = st.text_input(\"\", key=\"device_name\")\n",
    "geo_names = ['All', 'BR', 'MX', 'US', 'US', 'CA', 'IN', 'FR', 'DE', 'JP', 'AU', 'CN']\n",
    "if device_name:\n",
    "        with st.form(key='my_form'):\n",
    "            selected_geo = st.selectbox('Select an aspect to see consumer reviews:', geo_names)\n",
    "            selected_aspect = st.selectbox('Select an aspect to see consumer reviews:', aspect_names)\n",
    "            submitted = st.form_submit_button('Submit')\n",
    "            if submitted:\n",
    "                data_verbatims = sqldf(query_verbatims(\"Give me reviews of \" + device_name + \"for \" + selected_aspect + \"Aspect\" + \"from \" + selected_geo + \" Geography\"))\n",
    "                num_rows = data_verbatims.shape[0]\n",
    "                if num_rows > 900:\n",
    "                    data_verbatims_1 = data_verbatims.head(900)\n",
    "                else:\n",
    "                    data_verbatims_1 = data_verbatims\n",
    "                data_verbatims.to_csv(\"Verbatim.txt\", sep = '\\t')\n",
    "                a = \"Verbatim.txt\"\n",
    "                summary = query_to_embedding_summarize(\"Summarize the reviews of \"+  device_name + \"for \" + selected_aspect + \" Aspect\",a)\n",
    "                st.subheader(\"Summary\")\n",
    "                st.write(summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
